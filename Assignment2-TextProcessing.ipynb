{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Write a python program to find out the words after '@' from the below sentences with the use of regex.\n",
    "\n",
    "\"xyz@gmail.com\", \"abc@yahoo.com\", \"xyz@hotmail.com\", \"abc@ineuron.ai\", \"xyz@outlook.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def wordafter(text):\n",
    "    return re.findall('@(\\S+)',text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gmail.com', 'yahoo.com', 'hotmail.com', 'ineuron.ai', 'outlook.com']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"xyz@gmail.com\", \"abc@yahoo.com\", \"xyz@hotmail.com\", \"abc@ineuron.ai\", \"xyz@outlook.com\"]\n",
    "extract_word = []\n",
    "for sentence in sentences:\n",
    "    extract_word.append(wordafter(sentence))\n",
    "    \n",
    "extract_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Write a python program with the use of regex to take out the word \"New\" from the following sentence.\n",
    "\n",
    "[\"New Delhi is the capital of India\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=\"New Delhi is the capital of India\"\n",
    "re.findall(r'New',x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Create one python program in which you have to lowercase the sentence first and than delete digits from the following sentence.\n",
    "\n",
    "\"In India, 184 people got affected with Corona virus and 4 are died.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in india,  people got affected with corona virus and  are died.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_numremove(text):\n",
    "    result = re.sub(r'\\d+', '', text.lower()) \n",
    "    return result \n",
    "    \n",
    "sen=\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "lower_numremove(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Do stemming, lemmatization and tokenization from the following sentence.\n",
    "\n",
    "\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenization of the sentence is:\n",
      " ['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'savings', ',', 'I', 'will', 'be', 'able', 'to', 'travel', 'to', 'Hawai', '.'] \n",
      "\n",
      "Stemming of the words are:\n",
      " ['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'save', ',', 'I', 'will', 'be', 'abl', 'to', 'travel', 'to', 'hawai', '.'] \n",
      "\n",
      "Lemmatization of the words are:\n",
      " ['I', 'hope', 'that', ',', 'when', 'I', 'have', 'build', 'up', 'my', 'save', ',', 'I', 'will', 'be', 'able', 'to', 'travel', 'to', 'Hawai', '.']\n"
     ]
    }
   ],
   "source": [
    "stem=PorterStemmer()\n",
    "lemma=wordnet.WordNetLemmatizer()\n",
    "\n",
    "word_token=word_tokenize(\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\")\n",
    "print('The tokenization of the sentence is:\\n',word_token,'\\n')\n",
    "\n",
    "stems=[stem.stem(word) for word in word_token]\n",
    "print('Stemming of the words are:\\n',stems,'\\n')\n",
    "\n",
    "lemmas=[lemma.lemmatize(word,pos='v') for word in word_token]\n",
    "print('Lemmatization of the words are:\\n',lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Create one python program from the following sentence.\n",
    "\n",
    "\"I love NLP, not you\"\n",
    "\n",
    "output : ['I', 'l', 'N', 'n', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'l', 'N', 'n', 'y']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractfirst(text):\n",
    "    text_split=text.split(' ')\n",
    "    out=[]\n",
    "    for word in text_split:\n",
    "        out.append(re.findall(r'^\\w',word)[0])\n",
    "    return out\n",
    "\n",
    "text=\"I love NLP, not you\"\n",
    "extractfirst(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
